{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,random\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"THEANO_FLAGS\"]  = \"device=gpu%d\"%(1)\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import keras.models as models\n",
    "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.regularizers import *\n",
    "from keras.optimizers import adam\n",
    "import random, sys, keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from util import dataset_load\n",
    "\n",
    "datafile_src = 'radio_data_2018Aug03_04_06.data'\n",
    "#modelfile = 'QPSK.wts_model.h5'\n",
    "[X_train_src, Y_train_src, X_test_src, Y_test_src] = dataset_load(datafile_src)\n",
    "\n",
    "datafile_tar = 'radio_data_2018Aug03_04_10.data'\n",
    "[X_train_tar, Y_train_tar, X_test_tar, Y_test_tar] = dataset_load(datafile_tar)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((10000, 10000), 1) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import da_tool.tca\n",
    "my_tca = da_tool.tca.TCA(dim=3,kerneltype='rbf', kernelparam=1, mu=1)\n",
    "#x_src_tca = np.zeros([10000,2,4])\n",
    "#x_tar_tca = np.zeros([10000,2,4])\n",
    "#x_tar_o_tca = np.zeros([10000,2,4])\n",
    "#x_src_tca_test = np.zeros([10000,2,4])\n",
    "#x_tar_tca_test = np.zeros([10000,2,4])\n",
    "#x_tar_o_tca_test = np.zeros([10000,2,4])\n",
    "#for i in range(0,len(X_train_src)):\n",
    "X_train_src1 = np.reshape(X_train_src, [10000256])\n",
    "X_train_tar1 = np.reshape(X_train_tar, [10000, 256])\n",
    "\n",
    "x_src_tca, x_tar_tca, x_tar_o_tca = my_tca.fit_transform(X_train_src1, X_train_tar1)\n",
    "#    x_src_tca_test[i], x_tar_tca_test[i], x_tar_o_tca_test[i] = my_tca.fit_transform(X_test_src[i], X_test_tar[i])\n",
    "print(x_src_tca.shape)\n",
    "print(len(X_train_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2560000,)\n",
      "(2560000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_src.shape)\n",
    "\n",
    "print(X_train_src.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import da_tool.tca\n",
    "my_tca = da_tool.tca.TCA(dim=30,kerneltype='rbf', kernelparam=1, mu=1)\n",
    "x_src_tca = np.zeros([10000,2,4])\n",
    "x_tar_tca = np.zeros([10000,2,4])\n",
    "x_tar_o_tca = np.zeros([10000,2,4])\n",
    "x_src_tca_test = np.zeros([10000,2,4])\n",
    "x_tar_tca_test = np.zeros([10000,2,4])\n",
    "x_tar_o_tca_test = np.zeros([10000,2,4])\n",
    "for i in range(0,len(X_train_src)):\n",
    "    x_src_tca[i], x_tar_tca[i], x_tar_o_tca[i] = my_tca.fit_transform(X_train_src[i], X_train_tar[i])\n",
    "    x_src_tca_test[i], x_tar_tca_test[i], x_tar_o_tca_test[i] = my_tca.fit_transform(X_test_src[i], X_test_tar[i])\n",
    "print(x_src_tca.shape)\n",
    "print(x_tar_tca_test.shape)\n",
    "print(len(X_train_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepsensing_network(in_shp = [2, 4], classes = ['busy' ,'idle']):\n",
    "    K.set_image_dim_ordering('th')\n",
    "    dr = 0.5\n",
    "    model = models.Sequential()\n",
    "    model.add(Reshape([1]+in_shp, input_shape=in_shp))\n",
    "    model.add(ZeroPadding2D((0, 2)))\n",
    "    model.add(Convolution2D(256, 1, 3, border_mode='valid', activation=\"relu\", name=\"conv1\", init='glorot_uniform'))\n",
    "    model.add(Dropout(dr))\n",
    "    model.add(ZeroPadding2D((0, 2)))\n",
    "    model.add(Convolution2D(80, 2, 3, border_mode=\"valid\", activation=\"relu\", name=\"conv2\", init='glorot_uniform'))\n",
    "    model.add(Dropout(dr))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', init='he_normal', name=\"dense1\"))\n",
    "    model.add(Dropout(dr))\n",
    "    model.add(Dense( len(classes), init='he_normal', name=\"dense2\" ))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.add(Reshape([len(classes)]))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import dataset_load\n",
    "\n",
    "\n",
    "in_shp = [2,4]\n",
    "classes = ['busy', 'idle']\n",
    "batch_size = 1000\n",
    "nb_epoch = 100\n",
    "\n",
    "model = deepsensing_network(in_shp, classes)\n",
    "     \n",
    "history = model.fit(x_src_tca,\n",
    "                    Y_train_src,\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    verbose=2,\n",
    "                    validation_data=(x_src_tca_test, Y_test_src),\n",
    "        callbacks = [\n",
    "            keras.callbacks.ModelCheckpoint(modelfile, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n",
    "            keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "        ])\n",
    "\n",
    "model.load_weights(modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_hat = model.predict(x_tar_tca_test, batch_size=1000)\n",
    "\n",
    "pd, pf = cal_pd_pf(x_tar_tca_test, Y_test_tar, test_Y_hat)\n",
    "print(pd, pf)\n",
    "\n",
    "pds, pfs = cal_roc(x_tar_tca_test, Y_test_tar, test_Y_hat)\n",
    "\n",
    "plt.plot( pfs, pds)\n",
    "plt.xlabel('pfs')\n",
    "plt.ylabel('pds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pfs)\n",
    "print(pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import dataset_load\n",
    "\n",
    "datafile = 'radio_data_2018Aug03_03_46.data'\n",
    "modelfile = 'QPSK.wts_model.h5'\n",
    "\n",
    "[X_train, Y_train, X_test, Y_test] = dataset_load(datafile)\n",
    "\n",
    "in_shp = [2,128]\n",
    "classes = ['busy', 'idle']\n",
    "batch_size = 1000\n",
    "nb_epoch = 100\n",
    "\n",
    "model = deepsensing_network(in_shp, classes)\n",
    "     \n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_test, Y_test),\n",
    "        callbacks = [\n",
    "            keras.callbacks.ModelCheckpoint(modelfile, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n",
    "            keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "        ])\n",
    "\n",
    "model.load_weights(modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import  cal_roc, plot_roc, cal_pd_pf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datafile = 'radio_data_2018Aug03_04_10.data'\n",
    "\n",
    "[X_train, Y_train, X_test, Y_test] = dataset_load(datafile)\n",
    "\n",
    "test_Y_hat = model.predict(X_test, batch_size=1000)\n",
    "\n",
    "pd, pf = cal_pd_pf(X_test, Y_test, test_Y_hat)\n",
    "print(pd, pf)\n",
    "\n",
    "pds, pfs = cal_roc(X_test, Y_test, test_Y_hat)\n",
    "\n",
    "plt.plot( pfs, pds)\n",
    "plt.xlabel('pfs')\n",
    "plt.ylabel('pds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import da_tool.tca\n",
    "my_tca = da_tool.tca.TCA(dim=30,kerneltype='rbf', kernelparam=1, mu=1)\n",
    "x_src_tca, x_tar_tca, x_tar_o_tca = my_tca.fit_transform(X_test, X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
